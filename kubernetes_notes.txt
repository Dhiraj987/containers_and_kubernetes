                                                kubernetes

As the containerization increased, managing 100s and 1000s of containers with scripts was
very difficult. To solve this, google created kubernetes.

kubernetes is simply a container orchestration tool that offers
                                - high availability or reduced downtime  
                                - Scalability or high performance
                                - Disaster recovery or backup and restore

A deployment of kubernetes is called cluster.

Nodes are working physical or virtual machines in kubernetes. They are managed by control
 panel.


------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------

                                kubernetes OBJECTS
These are persistent entities in kubernetes. Once a user defines an object, K8s works to 
maintain it.


                                        PODS
These are the simplest units in kubernetes
They encapsulate a container or multiple containers, they are a level of abstraction
Creating their replicas serves to scale up an application horizontally

Each pod gets a service (permanent IP address) that they use to communicate with one another. 


In kubernetes, all we need to do is--

1. Start the cluster using minikube
2. Start a deployment-- it takes care of almost everything from creating pods to creating
                         replica sets. 
        In practice, we don’t manually create pods, the kubectl takes care of that while 
                                creating deployment.
             (deployment is an abstraction level over the pod and pod is an abstraction
                                         level for container)


                                Command to create a deployment:

        kubectl create deployment name-of-the-pod --image=image-name
this is Blueprint for creating pods 
this is the most basic configuration for deployment (name and image to use)
in this Everything else is set to default

-- we don’t need to manually start replicaset, deployment takes care of that; it always 
                start two copies of the pod to decrease chances of downtime
-- in deployment we can completely configure the blueprint of the pod (we can also 
                specify the number of pod to be created)


kubectl apply -f config_file.yaml is best way to run or create an object in kubernetes
        it updates and does all the things needed to reach the defined desired state.

Deployment name: nginx-depl
Replicaset name: nginx-depl-96979c6b8
Pod name: nginx-depl-96979c6b8-nfpwp


To edit the deployment, we do 
kubectl edit deployment
It opens a vim editor and we can make edits and save them. Once we save them, the engine 
        works to replace the old pod with new one
(i to get to insert mode; esc to get to executive command mode and then :w to write and :q 
                to exit || :wq for both at once)

------------------------------------------------------------------------------------------

                                ReplicaSet
Replicates pods for redundancy
Maintains desired state
It helps us scale application to meet demands and decrease down-time

When we create a deployment, K8s creates at least one replicas of it. (and more if we specify it)
        kubectl scale deploy deployment_name --replicas=3

We can manually create ReplicaSet by specifying kind: replicaset in the config yaml file

once we specify the no. of objects in kubernetes, kubernetes works to maintain that at all time, 
the same applies with replica sets

------------------------------------------------------------------------------------------

                                Autoscaling 
Horizontal Pod Autoscaler (HPA) enables automatic scaling up and scaling down as needed.
It can configure on desired state of CPU, memory, etc.

command for autoscale deployment- 
     kubectl autoscale deploy deployment_name --min=2 --max=5 --cpu-percentage=10

we can also set minReplicas, maxReplicas and targetCPUUtilizationPercentage in the yaml
         config file

-- Both replicaSet and AutoScaling are important to minimize downtime and service interruptions

------------------------------------------------------------------------------------------

                                        Rolling updates

- Rolling updates are a way to roll out app changes in an automated and controlled fashion 
        throughout your pods, users can always access the app as rolling updates takes care 
                of everything else
- It also allows for rollback when something goes wrong.

Step 1 to adding Rolling updates - add liveness and readiness probes to your deployments. 
        This ensures deployments are marked ready appropriately
Step 2 to  adding Rolling updates - add a rolling update strategy to the yaml config file
        sth like:-          strategy: 
                                type: RollingUpdate
                                rollingUpdate:
                                        maxUnavailable: 50%       (50% most be available)
                                        maxSurge: 2               (there can only be 2 extra
                                             replicas of pod than defined in the config file)

commands:- 
docker built -t hello_kubernetes .  → creates an image from a dockerfile at the current 
        directory and names it hello_kubernetes

docker tag hello_kubernetes upkar/hello_kubernetes:2.0    → applies the new tag to the image

docker push upkar/deployment_name:2.0                   → pushes the image to docker registry

kubectl set image deployments/deployment_name deployment_name=upkar/de

kubectl rollout status deployments/deployment_name      → returns the status of the rollout

kubectl rollout undo deployments/deployment_name    → if the rollout needs to be backed 
        down, rolling updates provides us with an opportunity to do that as well.

------------------------------------------------------------------------------------------
                Config maps and Secrets

We avoid hardcoded configuration variables, in docker and kubernetes we do so via 
config maps and secrets  (Account ID, passwords, API keys)

-- We use config maps to provide configuration for deployments
-- They can be reused across deployments
-- To create config maps, we can 
        - use string literals
        - Use key value pairs
        - use a config map yaml descriptive file

secrets do the same but are used for sensitive information 

config maps and secrets are used by deployments just before they are run

command
        kubectl create configmap my-config --from-literal=MESSAGE='hello from the config map'

in the config yaml file-

env: 
  -name:MESSAGE
  valuefrom:
    configMapKeyRef:
        name:my-config
        key:MESSAGE


        kubectl get configmaps/secrets
        kubectl describe configmap/secrets configmap_name



Step 1: create a secret or config map
Step 2: check if it was actually created
Step 3: (we can also use the describe command to look into the file)
Step 4: add the the config map/ secret in the deployment descriptor 
                or the config file


------------------------------------------------------------------------------------------                

IN GENERAL-
1. create a dockerfile
2. crate an image out of it
3. create a config yaml file for deployment 
4. use the yaml to create deployment

------------------------------------------------------------------------------------------

To expose/ access the application for use
kubectl expose deployment/deployment_name

Cluster IPs are only accessible within the cluster. To make this externally accessible, 
we can create a proxy. this is not how you would make an application externally accessible 
in a production scenario.
kubectl proxy

the command below pings the application to get a response.
curl -L localhost:8001/api/v1/namespaces/sn-labs-$USERNAME/services/hello-world/proxy


the command below can be used to scale up the Deployment
kubectl scale deployment hello-world --replicas=3


for i in `seq 10`; do curl -L localhost:8001/api/v1/namespaces/services/hello-world/proxy; done


Perform rolling updates
let's first build a new version of our application and push it to Container Registry.

kubectl set image deployment/hello-world hello-world=us.icr.io/$MY_NAMESPACE/hello-world:2

command to getting the status of the rolling update
kubectl rollout status deployment/hello-world

the command to get more (wide) details for a  Deployment
kubectl get deployments -o wide

------------------------------------------------------------------------------------------

                                The Kubernetes Ecosystem

The services that are not directly provided by kubernetes but others host and it can be 
hooked up with kubernetes lies under the kubernetes ecosystem.

"Kubernetes is a portable, extensible, open-source platform for managing containerized 
workloads and services that facilitates both declarative configuration and automation. It 
has large, rapidly growing  ecosystem. Kubernetes services, support and tools are widely 
available"  -Kubernetes Documentation

things that Kubernetes alone doesn't provide- 
        - building container images
        - storing images in a container registry 
        - logging
        - monitoring
        - Continuous Integration and Continuos Deployment

------------------------------------------------------------------------------------------

BIG PICTURE From Cloud Native (cncf.io) Trail Map :- 
1. Containerize the app
2. CI/CD 
3. orchestration and application definition
4. observation and analysis
5. service proxy, discovery and mesh
6. networking, policy and security
7. Distributed database and storage
8. streaming and messaging
9. container registry and runtime
10. Software Distribution

------------------------------------------------------------------------------------------

OpenShift is a platform that allows us to run containerized applications and workloads with
kubernetes under the hood. OKD (origin kuberenetes distribution) powers the OpenShift.

OpenShift builds on Kubernetes, docker (container runtime), OKD, STL, etc. to provide a more 
comprehensive container platform.
OpenShift adds developer and operations centric tooling on top of kubernetes

OpenShift offers logging, monitoring, container registry, networking, router, kubevirt and 
other features. 

                                 OpenShift

------------------------------------------------------------------------------------------
|               Red Hat Enterprises Linux & Red Hat Enterprise Linux CoreOS              |
------------------------------------------------------------------------------------------
|                                       kuberenetes                                      |
------------------------------------------------------------------------------------------
|                                        Cluster Services                                |
| Automated ops | Over-the-air updates | Monitoring | Registry | Networking | OLM | Helm |
------------------------------------------------------------------------------------------
|        Platform Services           |    Application Services   |   Developer Services  |
| Service mesh | Serverless builds   | Databases | Languages     | Developer CLI | IDE   |
|    CI/CD pipelines | Full Stack    |  Runtimes | Integration   | extensions and plugins|
|        logging | Chargeback        |     100+ ISV services     | codeready containers  |
------------------------------------------------------------------------------------------


Similarities between Kubernetes and OpenShift
- Kubernetes capabilities
- Container orchestration
- both are open source

Differences between Kubernetes and OpenShift

                        Kubernetes              OpenShift
                         Project                 Product 
                         kubectl                 oc cli
                    not that useful UI         has web UI 
                        Deployment          DeploymentConfig
      
------------------------------------------------------------------------------------------

Continuous Integration - Continuous Deployment is the automation of changes in the codebase 
        to delivery

Automatically build, test, and merge →  Automatically release to a repository  →  Automatic 
                                                                                deploy
 
------------------------------------------------------------------------------------------

                                Build
build is the process of transforming inputs into a resultant objects 

buildconfig is openshift specific object that defines the process for a build to follow.
buildconfig is a blueprint, build is an instance of buildconfig

------------------------------------------------------------------------------------------

                        Source - to - Image (S2I)

Its a tool for building reproducible container image, offered by openshift
-- It injects application source into a container to produce a ready-to-run image
-- Eliminates the need to write a dockerfile

With this feature, we don't need to worry for writing a docker file or even running the 
build command, we push our code and openshift creates an image for us.
(GTK) the new image created here uses a builder image (openshift includes a predefined 
builder image) and the source code.
- all of this enables us to go from source code to image, saving time and effort

------------------------------------------------------------------------------------------

                        Custom Build

Its similar to S2I but a slightly advanced strategy. 
-- the user needs to define a builder image
-- the custom builder images are docker images that contains the logic needed to transform 
        inputs into the expected output (python package, jar or any other formats for 
                                resulting object)

------------------------------------------------------------------------------------------

